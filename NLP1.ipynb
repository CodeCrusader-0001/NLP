{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --quiet\n",
        "\n",
        "import re\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Load streaming dataset\n",
        "dataset = load_dataset(\"ai4bharat/IndicCorpV2\", \"indiccorp_v2\", split=\"hin_Deva\", streaming=True)\n",
        "\n",
        "# 2. Tokenizers\n",
        "def sentence_tokenizer(text):\n",
        "    sentence_endings = re.compile(r'(?<=[।.!?])\\s+')\n",
        "    return [s.strip() for s in sentence_endings.split(text.strip()) if s.strip()]\n",
        "\n",
        "def word_tokenizer(sentence):\n",
        "    token_pattern = re.compile(r\"\"\"\n",
        "        (https?://[^\\s]+) |\n",
        "        ([\\w\\.-]+@[\\w\\.-]+) |\n",
        "        (\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}) |\n",
        "        (\\d+\\.\\d+) |\n",
        "        (\\w+([-']\\w+)*) |\n",
        "        ([^\\w\\s])\n",
        "    \"\"\", re.VERBOSE | re.UNICODE)\n",
        "\n",
        "    return [m.group() for m in token_pattern.finditer(sentence)]\n",
        "\n",
        "# 3. Stats accumulators\n",
        "sentence_count = 0\n",
        "word_count = 0\n",
        "char_count = 0\n",
        "vocab_counter = Counter()\n",
        "MAX_DOCS = 1000\n",
        "\n",
        "# 4. Save tokenized sentences\n",
        "with open(\"tokenized_sentences.txt\", \"w\", encoding=\"utf-8\") as f_out:\n",
        "    for i, example in tqdm(enumerate(dataset), total=MAX_DOCS):\n",
        "        if i >= MAX_DOCS:\n",
        "            break\n",
        "\n",
        "        text = example[\"text\"]\n",
        "        sentences = sentence_tokenizer(text)\n",
        "        sentence_count += len(sentences)\n",
        "\n",
        "        for s in sentences:\n",
        "            tokens = word_tokenizer(s)\n",
        "            word_count += len(tokens)\n",
        "            char_count += sum(len(tok) for tok in tokens)\n",
        "            vocab_counter.update(tokens)\n",
        "\n",
        "            f_out.write(\" \".join(tokens) + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAhE3ilWaYok",
        "outputId": "bae8971d-b403-4f75-b027-b25f195eff42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1164.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tokens = len(vocab_counter)\n",
        "ttr = unique_tokens / word_count if word_count else 0\n",
        "avg_sent_len = word_count / sentence_count if sentence_count else 0\n",
        "avg_word_len = char_count / word_count if word_count else 0\n",
        "\n",
        "print(f\"Total Sentences: {sentence_count}\")\n",
        "print(f\"Total Words: {word_count}\")\n",
        "print(f\"Total Characters: {char_count}\")\n",
        "print(f\"Average Sentence Length (words): {avg_sent_len:.2f}\")\n",
        "print(f\"Average Word Length (chars): {avg_word_len:.2f}\")\n",
        "print(f\"Type/Token Ratio (TTR): {ttr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs29IazxdBug",
        "outputId": "bcff24ba-4240-422d-ab35-259bb4ab9776"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sentences: 1717\n",
            "Total Words: 106070\n",
            "Total Characters: 126919\n",
            "Average Sentence Length (words): 61.78\n",
            "Average Word Length (chars): 1.20\n",
            "Type/Token Ratio (TTR): 0.0180\n"
          ]
        }
      ]
    }
  ]
}