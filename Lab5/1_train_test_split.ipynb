{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfda6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff9638a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 sentence\n",
      "109927  हालातों का जायजा लेने सीएम तीरथ रावत खुद घटना ...\n",
      "474873  विकास खंड जैतपुर में तैनात तकनीकी सहायक अरविद ...\n",
      "982948  तथा उनके निशानदेही पर मुफ्फसिल थाना क्षेत्र अं...\n",
      "169235  यहां तक कि कई बार ऐसा भी दिखता है जब मायावती क...\n",
      "901156                      आसपास है पार्क , करें पौधरोपण\n",
      "839641                                              औशकोश\n",
      "502751  कुछ घटनाएं आपके प्रतिकूल हो सकती हैं तो कुछ अन...\n",
      "456206            ये नाला आगे जाकर कच्ची फाटक तक जाना है।\n",
      "988571  कोडरमा ( झारखंड ) : झारखंड की राजधानी रांची से...\n",
      "147948  चन्दाबाई द्वारा स्थापित श्री जैन बाला विश्राम ... \n",
      "\n",
      "\n",
      "Total sentences: 1000000\n"
     ]
    }
   ],
   "source": [
    "with open(r\"C:\\Users\\ashis\\OneDrive\\Desktop\\NLP\\LAB1\\sentence_tokenized.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sentences = [line.strip() for line in f if line.strip()]  \n",
    "\n",
    "# Wrap in DataFrame for convenience\n",
    "df = pd.DataFrame(sentences, columns=[\"sentence\"])\n",
    "\n",
    "# Show 10 random sentencesk\n",
    "print(df.sample(10),\"\\n\\n\")\n",
    "print(\"Total sentences:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f519f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "indices=np.random.permutation(len(df))\n",
    "\n",
    "val_idx =indices[:1000]\n",
    "test_idx=indices[1000:2000]\n",
    "train_idx =indices[2000:]\n",
    "\n",
    "val=df.iloc[val_idx]\n",
    "test=df.iloc[test_idx]\n",
    "train=df.iloc[train_idx]\n",
    "\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2454806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits saved successfully.\n"
     ]
    }
   ],
   "source": [
    "train.to_csv(\"train_sentences.csv\", index=False, encoding=\"utf-8\")\n",
    "val.to_csv(\"val_sentences.csv\", index=False, encoding=\"utf-8\")\n",
    "test.to_csv(\"test_sentences.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Data splits saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
